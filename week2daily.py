import streamlit as st
import pandas as pd
import datetime
import hashlib
import io
from pathlib import Path
import re

# ================================================
# ë“€ì–¼ CSV ì²´í¬ì•± (ì‹¬í”Œ)
#   - A = virtual.csv (í˜•ì‹ ììœ ) â†’ "ê·¸ëŒ€ë¡œ DataFrame" ìœ¼ë¡œ ìƒë‹¨ ê³ ì • ì˜ì—­ì— í‘œì‹œë§Œ í•¨
#   - B = week.csv    (ìš”ì¼ë³„ íƒœìŠ¤í¬) â†’ ì²´í¬ë¦¬ìŠ¤íŠ¸/ì§„í–‰ë¥ ì˜ ìœ ì¼í•œ ë°ì´í„° ì†ŒìŠ¤
#   - ì—…ë¡œë“œí•œ íŒŒì¼ì€ ì„¸ì…˜ì— ê³ ì •(ë‹¤ë¥¸ íŒŒì¼ ì˜¬ë¦´ ë•Œê¹Œì§€ ìœ ì§€)
# ================================================

st.set_page_config(page_title="ì£¼ê°„ ì²´í¬ë¦¬ìŠ¤íŠ¸ â€” ë“€ì–¼ CSV(ì‹¬í”Œ)", layout="wide")
st.title("âœ… ì£¼ê°„ ì²´í¬ë¦¬ìŠ¤íŠ¸ â€” ë“€ì–¼ CSV (ì‹¬í”Œ)")
st.caption("A(virtual)ëŠ” ê·¸ëƒ¥ í‘œë¡œ ë³´ì—¬ì£¼ê³ , B(week)ë§Œ ì²´í¬/ì§„í–‰ë¥ ì— ì‚¬ìš©í•©ë‹ˆë‹¤.")

DAYS_KR = ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"]

# ---------------------
# Helpers
# ---------------------
def _parse_pipe_or_lines(s: str):
    if s is None or (isinstance(s, float) and pd.isna(s)):
        return []
    s = str(s)
    if "|" in s:
        parts = [x.strip() for x in s.split("|")]
    else:
        parts = []
        for sep in ["\n", ","]:
            if sep in s:
                parts = [x.strip() for x in s.split(sep)]
                break
        if not parts:
            parts = [s.strip()]
    return [x for x in parts if x]

def _stable_task_key(week_id: str, day: str, prefix: str, text: str) -> str:
    raw = f"{week_id}|{day}|{prefix}|{text}"
    return "chk_" + hashlib.md5(raw.encode("utf-8")).hexdigest()

# Bìš©(week.csv) ìœ ì—° ë¡œë” â€” ìµœì†Œ ìš”ê±´: ìš”ì¼ + (ë©”ì¸ ì¹¼ëŸ¼ í•˜ë‚˜) + (ë°°ê²½ ì¹¼ëŸ¼ í•˜ë‚˜)
HEADER_ALIASES = {
    "day": ["ìš”ì¼", "day", "ì¼ì"],
    "main": ["ìƒì„¸ í”Œëœ(ë©”ì¸)", "ë©”ì¸", "main", "í¬ì»¤ìŠ¤", "focus"],
    "routine": ["ìƒì„¸ í”Œëœ(ë°°ê²½)", "ë°°ê²½", "routine", "background"],
}
_DEF_MAIN = "ìƒì„¸ í”Œëœ(ë©”ì¸)"
_DEF_ROUT = "ìƒì„¸ í”Œëœ(ë°°ê²½)"

def _norm_header(s: str) -> str:
    s = str(s).strip().lower()
    s = re.sub(r"\s+", "", s)
    return s.replace("_", "")

def _pick(df: pd.DataFrame, keys: list[str]):
    # ì™„ì „ì¼ì¹˜ â†’ ë¶€ë¶„í¬í•¨ ìˆœ
    cols = list(df.columns)
    by_norm = {_norm_header(c): c for c in cols}
    for k in keys:
        if _norm_header(k) in by_norm:
            return by_norm[_norm_header(k)]
    for c in cols:
        nc = _norm_header(c)
        if any(_norm_header(k) in nc for k in keys):
            return c
    return None

def load_week_like(file) -> pd.DataFrame:
    """
    CSVë¥¼ ì½ì–´ ì•„ë˜ 6ê°œ ì»¬ëŸ¼ì„ 'í•­ìƒ' ê°–ë„ë¡ ì •ê·œí™”í•´ì„œ ëŒë ¤ì¤ë‹ˆë‹¤.
      - ìš”ì¼, ë‚ ì§œ, ìë™ ì œì•ˆ(ë©”ì¸), ìë™ ì œì•ˆ(ë°°ê²½), ìƒì„¸ í”Œëœ(ë©”ì¸), ìƒì„¸ í”Œëœ(ë°°ê²½)
    ì›ë³¸ CSVì— ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´("")ë¡œ ì±„ìš°ê³ , í—¤ë”ëŠ” ìœ ì—°í•˜ê²Œ ë§¤í•‘í•©ë‹ˆë‹¤.
    """
    file.seek(0)
    try:
        df = pd.read_csv(file, encoding="utf-8-sig")
    except UnicodeDecodeError:
        file.seek(0)
        df = pd.read_csv(file, encoding="utf-8")

    # ---- ì»¬ëŸ¼ í›„ë³´ (ìœ ì—° ë§¤í•‘) ----
    # ìš”ì¼/ë©”ì¸/ë°°ê²½ì€ ê¸°ì¡´ ë³„ì¹­ ì‚¬ìš©
    day_aliases  = HEADER_ALIASES["day"]          # ["ìš”ì¼","day","ì¼ì"]
    main_aliases = HEADER_ALIASES["main"]         # ["ìƒì„¸ í”Œëœ(ë©”ì¸)","ë©”ì¸","main","í¬ì»¤ìŠ¤","focus"]
    rout_aliases = HEADER_ALIASES["routine"]      # ["ìƒì„¸ í”Œëœ(ë°°ê²½)","ë°°ê²½","routine","background"]

    # ì¶”ê°€: ë‚ ì§œ/ìë™ì œì•ˆ ë³„ì¹­
    date_aliases      = ["ë‚ ì§œ", "date", "ì¼ì", "ë‚ ì§œ(yyyy-mm-dd)", "ë‚ ì§œ(YYYY-MM-DD)"]
    auto_main_aliases = ["ìë™ ì œì•ˆ(ë©”ì¸)", "ìë™ì œì•ˆ(ë©”ì¸)", "ìë™ì œì•ˆë©”ì¸", "ì œì•ˆ(ë©”ì¸)", "ì œì•ˆë©”ì¸", "auto_main", "suggest_main"]
    auto_rout_aliases = ["ìë™ ì œì•ˆ(ë°°ê²½)", "ìë™ì œì•ˆ(ë°°ê²½)", "ìë™ì œì•ˆë°°ê²½", "ì œì•ˆ(ë°°ê²½)", "ì œì•ˆë°°ê²½", "auto_routine", "suggest_routine"]

    # ---- ìœ ì—° ë§¤í•‘ í”½ ----
    day_col       = _pick(df, day_aliases)
    date_col      = _pick(df, date_aliases)
    main_col      = _pick(df, main_aliases)
    rout_col      = _pick(df, rout_aliases)
    auto_main_col = _pick(df, auto_main_aliases)
    auto_rout_col = _pick(df, auto_rout_aliases)

    # ---- í•„ìˆ˜ ìµœì†Œ ìš”ê±´: 'ìš”ì¼'ì€ ìˆì–´ì•¼ í•¨ ----
    if day_col is None:
        raise ValueError(f"B íŒŒì¼ì— 'ìš”ì¼'ì— í•´ë‹¹í•˜ëŠ” ì¹¼ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. CSV í—¤ë”: {list(df.columns)}")

    # ---- ëˆ„ë½ëœ ì»¬ëŸ¼ì€ ë¹ˆ ë¬¸ìì—´ë¡œ ë§Œë“¤ì–´ ì±„ì›Œ ë„£ê¸° ----
    if date_col is None:
        df["__ë‚ ì§œ__"] = ""
        date_col = "__ë‚ ì§œ__"
    if main_col is None:
        df["__ìƒì„¸ë©”ì¸__"] = ""
        main_col = "__ìƒì„¸ë©”ì¸__"
    if rout_col is None:
        df["__ìƒì„¸ë°°ê²½__"] = ""
        rout_col = "__ìƒì„¸ë°°ê²½__"
    if auto_main_col is None:
        df["__ìë™ë©”ì¸__"] = ""
        auto_main_col = "__ìë™ë©”ì¸__"
    if auto_rout_col is None:
        df["__ìë™ë°°ê²½__"] = ""
        auto_rout_col = "__ìë™ë°°ê²½__"

    # ---- ì¶œë ¥ ìŠ¤í‚¤ë§ˆ êµ¬ì„± ----
    out = df[[day_col, date_col, auto_main_col, auto_rout_col, main_col, rout_col]].copy()
    out.columns = ["ìš”ì¼", "ë‚ ì§œ", "ìë™ ì œì•ˆ(ë©”ì¸)", "ìë™ ì œì•ˆ(ë°°ê²½)", "ìƒì„¸ í”Œëœ(ë©”ì¸)", "ìƒì„¸ í”Œëœ(ë°°ê²½)"]

    # ---- ì •ë¦¬/ì •ë ¬ ----
    out = out.fillna("")
    # ìš”ì¼ ì¹´í…Œê³ ë¦¬ ì •ë ¬ (ì¡´ì¬í•˜ëŠ” í–‰ë§Œ ë°˜ì˜)
    cat = pd.CategoricalDtype(categories=DAYS_KR, ordered=True)
    out["ìš”ì¼"] = pd.Categorical(out["ìš”ì¼"].astype(str).str.strip(), dtype=cat)
    out = out.sort_values("ìš”ì¼").reset_index(drop=True)

    return out


# ---------------------
# Sidebar â€” A/B ì—…ë¡œë“œ ë° ê³ ì •
# ---------------------
with st.sidebar:
    st.markdown("### ğŸ“ CSV ì—…ë¡œë“œ (A=virtual, B=week)")
    colA, colB = st.columns(2)
    with colA:
        upA = st.file_uploader("A: virtual.csv", type=["csv"], key="uA")
    with colB:
        upB = st.file_uploader("B: week.csv (ìš”ì¼/ë©”ì¸/ë°°ê²½)", type=["csv"], key="uB")

    if "persist_A" not in st.session_state:
        st.session_state.persist_A = None  # {name, bytes}
    if "persist_B" not in st.session_state:
        st.session_state.persist_B = None

    c1, c2, c3 = st.columns([2,2,2])
    with c1:
        if st.button("A ì €ì¥/ê°±ì‹ ", use_container_width=True) and upA is not None:
            upA.seek(0)
            st.session_state.persist_A = {"name": upA.name, "bytes": upA.read()}
            st.success(f"A ê³ ì •: {upA.name}")
    with c2:
        if st.button("B ì €ì¥/ê°±ì‹ ", use_container_width=True) and upB is not None:
            upB.seek(0)
            st.session_state.persist_B = {"name": upB.name, "bytes": upB.read()}
            st.success(f"B ê³ ì •: {upB.name}")
    with c3:
        if st.button("ëª¨ë‘ í•´ì œ", use_container_width=True):
            st.session_state.persist_A = None
            st.session_state.persist_B = None
            st.success("ë‘ íŒŒì¼ ëª¨ë‘ í•´ì œë¨")

    st.caption("AëŠ” í‘œë¡œë§Œ ë³´ì—¬ì£¼ê³ , Bë§Œ ì²´í¬/ì§„í–‰ë¥ ì— ì‚¬ìš©í•©ë‹ˆë‹¤. ì—…ë¡œë“œëœ íŒŒì¼ì€ ë³€ê²½ ì „ê¹Œì§€ ìœ ì§€ë©ë‹ˆë‹¤.")

# ì¤€ë¹„ëœ ë°”ì´íŠ¸ â†’ íŒŒì¼í•¸ë“¤
A_blob = st.session_state.get("persist_A")
B_blob = st.session_state.get("persist_B")
A_name = A_blob["name"] if A_blob else None
B_name = B_blob["name"] if B_blob else None
A_file = io.BytesIO(A_blob["bytes"]) if A_blob else None
B_file = io.BytesIO(B_blob["bytes"]) if B_blob else None

if "completed_by_day" not in st.session_state:
    st.session_state.completed_by_day = {}

# ---------------------
# ìƒë‹¨ ê³ ì •: ë‘ íŒŒì¼ ëª¨ë‘ ë³´ì—¬ì£¼ê¸° (AëŠ” ê·¸ëŒ€ë¡œ df, BëŠ” ìš”ì•½í‘œ)
# ---------------------
st.markdown(
    """
    <style>
    .sticky-plan {position: sticky; top: 0; z-index: 999; background: var(--background-color); padding: 0.5rem 0.25rem; border-bottom: 1px solid rgba(0,0,0,0.08);} 
    .sticky-card {padding: 0.5rem 0.75rem; border: 1px solid rgba(0,0,0,0.08); border-radius: 10px; margin-bottom: 8px;}
    .sticky-table {font-size: 0.92rem; width: 100%; border-collapse: collapse;}
    .sticky-table th, .sticky-table td {padding: 6px 8px; vertical-align: top; border-bottom: 1px dashed rgba(0,0,0,0.06);} 
    .day {font-weight: 600; white-space: nowrap;}
    .muted {opacity: .7; font-size: .85rem;}
    </style>
    """,
    unsafe_allow_html=True,
)

# A í‘œ ë¯¸ë¦¬ì½ê¸° (ê·¸ëŒ€ë¡œ í‘œì‹œ)
A_df = None
if A_file is not None:
    try:
        A_file.seek(0)
        try:
            A_df = pd.read_csv(A_file, encoding="utf-8-sig")
        except UnicodeDecodeError:
            A_file.seek(0)
            A_df = pd.read_csv(A_file)
    except Exception as e:
        st.warning(f"A íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

# B ìš”ì•½í‘œ êµ¬ì„±(ìš”ì¼/ë©”ì¸/ë°°ê²½ì´ ìˆëŠ” ê²½ìš°)
B_df = None
if B_file is not None:
    try:
        B_df = load_week_like(B_file)
    except Exception as e:
        st.warning(f"B íŒŒì¼ í•´ì„ ì˜¤ë¥˜: {e}")

# Sticky HTML/controls
st.markdown("<div class='sticky-plan'>", unsafe_allow_html=True)

if A_df is not None:
    st.markdown(f"**ğŸ“Œ A(virtual) â€” {A_name}**")
    st.dataframe(A_df.head(50), use_container_width=True)
    st.download_button("ğŸ“¥ A ë‹¤ìš´ë¡œë“œ", data=A_blob.get("bytes", b""), file_name=A_name or "virtual.csv", mime="text/csv", key="dlA")
else:
    st.markdown("**ğŸ“Œ A(virtual)**: (íŒŒì¼ ì—†ìŒ ë˜ëŠ” ì½ê¸° ì‹¤íŒ¨)")

if B_df is not None:
    st.markdown(f"**ğŸ“Œ B(week) â€” {B_name} (ìš”ì¼Â·ë©”ì¸Â·ë°°ê²½ ìš”ì•½)**")
    st.dataframe(B_df, use_container_width=True)
    st.download_button("ğŸ“¥ B ë‹¤ìš´ë¡œë“œ", data=B_blob.get("bytes", b""), file_name=B_name or "week.csv", mime="text/csv", key="dlB")
else:
    st.markdown("**ğŸ“Œ B(week)**: (íŒŒì¼ ì—†ìŒ ë˜ëŠ” í•´ì„ ë¶ˆê°€ â€” ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¹„í™œì„±í™”)")

st.markdown("</div>", unsafe_allow_html=True)

# ---------------------
# ì²´í¬ë¦¬ìŠ¤íŠ¸(ì˜¤ì§ Bë¡œë§Œ!)
# ---------------------
if B_df is None:
    st.info("B(week) íŒŒì¼ì´ ìˆì–´ì•¼ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ìš”.")
    st.stop()

# ìš”ì¼ â†’ íƒœìŠ¤í¬ ë§¤í•‘ (B)
B_map = {}
ordered_days = []
for _, row in B_df.iterrows():
    d = str(row["ìš”ì¼"]) if row["ìš”ì¼"] == row["ìš”ì¼"] else ""
    if not d:
        continue
    mains = _parse_pipe_or_lines(row.get(_DEF_MAIN, ""))
    routines = _parse_pipe_or_lines(row.get(_DEF_ROUT, ""))
    B_map[d] = {"main": mains, "routine": routines}
    if d not in ordered_days:
        ordered_days.append(d)
ordered_days = [d for d in DAYS_KR if d in ordered_days]

# ì˜¤ëŠ˜ ìš”ì¼ ìë™ ì¸ì‹ (ìˆ˜ë™ ë³€ê²½ ê°€ëŠ¥)
_today = datetime.date.today()
auto_idx = min(_today.weekday(), 6)
sel_day = st.radio(
    "ğŸ—“ ì˜¤ëŠ˜ ìš”ì¼ ì„ íƒ",
    ordered_days,
    index=ordered_days.index(DAYS_KR[auto_idx]) if DAYS_KR[auto_idx] in ordered_days else 0,
    horizontal=True,
)

week_id = Path(B_name or "week").stem
main_tasks = B_map[sel_day]["main"]
routine_tasks = B_map[sel_day]["routine"]
all_tasks = [("[ë©”ì¸]", t) for t in main_tasks] + [("[ë°°ê²½]", t) for t in routine_tasks]

if (week_id, sel_day) not in st.session_state.completed_by_day:
    st.session_state.completed_by_day[(week_id, sel_day)] = set()
completed = st.session_state.completed_by_day[(week_id, sel_day)]

st.subheader(f"{sel_day} ì²´í¬ë¦¬ìŠ¤íŠ¸")
if not all_tasks:
    st.info("í•´ë‹¹ ìš”ì¼ì— ë“±ë¡ëœ íƒœìŠ¤í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    for kind, text in all_tasks:
        label = f"{kind} {text}"
        key = _stable_task_key(week_id, sel_day, kind, text)
        checked = st.checkbox(label, value=(label in completed), key=key)
        if checked:
            completed.add(label)
        else:
            completed.discard(label)

    pct_day = int(len(completed) / len(all_tasks) * 100) if all_tasks else 0
    st.progress(pct_day)
    st.write(f"ğŸ“Š **{sel_day} ë‹¬ì„±ë¥ **: {pct_day}%")

# ---------------------
# ì£¼ê°„ ì§‘ê³„ (B ê¸°ì¤€)
# ---------------------
st.markdown("---")
st.markdown("### ğŸ§® ì£¼ê°„ ì§„í–‰ë¥  (B ê¸°ì¤€)")
rows = []
weekly_total = 0
weekly_done = 0
for d in ordered_days:
    tasks_d = [("[ë©”ì¸]", t) for t in B_map[d]["main"]] + [("[ë°°ê²½]", t) for t in B_map[d]["routine"]]
    total_d = len(tasks_d)
    done_set = st.session_state.completed_by_day.get((week_id, d), set())
    done_d = len(done_set)
    weekly_total += total_d
    weekly_done += done_d
    pct_d = int((done_d/total_d)*100) if total_d else 0
    rows.append({"ìš”ì¼": d, "ì „ì²´": total_d, "ì™„ë£Œ": done_d, "ë‹¬ì„±ë¥ (%)": pct_d})

if rows:
    st.dataframe(pd.DataFrame(rows), use_container_width=True)
    pct_week = int((weekly_done/weekly_total)*100) if weekly_total else 0
    st.success(f"**ì£¼ê°„ í•©ê³„** â€” ì™„ë£Œ {weekly_done} / ì „ì²´ {weekly_total} â†’ ë‹¬ì„±ë¥  **{pct_week}%**")
else:
    st.caption("í‘œì‹œí•  ì£¼ê°„ ì§‘ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ---------------------
# (ì„ íƒ) ë‚´ë³´ë‚´ê¸°
# ---------------------
with st.expander("ğŸ“¤ í˜„ ì§„í–‰ìƒíƒœ CSVë¡œ ë‚´ë³´ë‚´ê¸° (B ê¸°ì¤€)", expanded=False):
    out_rows = []
    for d in ordered_days:
        tasks_d = [("[ë©”ì¸]", t) for t in B_map[d]["main"]] + [("[ë°°ê²½]", t) for t in B_map[d]["routine"]]
        done_set = st.session_state.completed_by_day.get((week_id, d), set())
        for kind, text in tasks_d:
            label = f"{kind} {text}"
            out_rows.append({"ìš”ì¼": d, "ìœ í˜•": kind, "í•  ì¼": text, "ì™„ë£Œ": (label in done_set)})
    if out_rows:
        out_df = pd.DataFrame(out_rows)
        st.download_button(
            "ğŸ“¥ ì§„í–‰ìƒíƒœ CSV ë‹¤ìš´ë¡œë“œ",
            data=out_df.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"progress_{week_id}.csv",
            mime="text/csv",
        )
    else:
        st.caption("ë‚´ë³´ë‚¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
